# üìñ Gu√≠a de Despliegue Paso a Paso

**De cero a producci√≥n: Tutorial completo para principiantes**

Esta gu√≠a te llevar√° desde la instalaci√≥n inicial hasta tener un sistema completo de NLP corriendo en Docker, paso a paso, sin asumir conocimientos previos.

---

## üìã Tabla de Contenidos

1. [Antes de Empezar](#antes-de-empezar)
2. [Fase 1: Configuraci√≥n del Entorno](#fase-1-configuraci√≥n-del-entorno)
3. [Fase 2: Ejecutando los Ejercicios (M√≥dulos 1-4)](#fase-2-ejecutando-los-ejercicios-m√≥dulos-1-4)
4. [Fase 3: Creando tu API con FastAPI](#fase-3-creando-tu-api-con-fastapi)
5. [Fase 4: Dockerizaci√≥n](#fase-4-dockerizaci√≥n)
6. [Fase 5: Monitoreo y Observabilidad](#fase-5-monitoreo-y-observabilidad)
7. [Fase 6: Despliegue Completo con Docker Compose](#fase-6-despliegue-completo-con-docker-compose)
8. [Soluci√≥n de Problemas Comunes](#soluci√≥n-de-problemas-comunes)
9. [Verificaci√≥n y Testing](#verificaci√≥n-y-testing)
10. [Pr√≥ximos Pasos](#pr√≥ximos-pasos)

---

## üéØ Antes de Empezar

### ¬øQu√© vamos a lograr?

Al final de esta gu√≠a, tendr√°s:
- ‚úÖ Un entorno Python configurado correctamente
- ‚úÖ 15 ejercicios ejecutados y entendidos
- ‚úÖ Una API REST funcionando con FastAPI
- ‚úÖ Tu aplicaci√≥n corriendo en Docker
- ‚úÖ Monitoreo con Prometheus
- ‚úÖ Un sistema completo listo para producci√≥n

### ¬øQu√© necesitas tener instalado?

| Software | Versi√≥n M√≠nima | ¬øD√≥nde descargarlo? |
|----------|---------------|---------------------|
| **Python** | 3.8+ (recomendado 3.12) | https://www.python.org/downloads/ |
| **Docker Desktop** | 24.0+ | https://www.docker.com/products/docker-desktop/ |
| **Git** | 2.30+ | https://git-scm.com/downloads |
| **Editor de c√≥digo** | Cualquiera | VS Code recomendado: https://code.visualstudio.com/ |

### ¬øCu√°nto tiempo tomar√°?

- **Configuraci√≥n inicial**: 30 minutos
- **M√≥dulos 1-4**: 30-40 horas (distribuidas)
- **M√≥dulo 5 (Despliegue)**: 6-9 horas
- **Total**: Puedes completarlo en 1-2 semanas trabajando 3-4 horas diarias

---

## üõ†Ô∏è Fase 1: Configuraci√≥n del Entorno

### Paso 1.1: Verifica que Python est√© instalado

**Windows:**
```cmd
python --version
```

**Linux/Mac:**
```bash
python3 --version
```

**¬øQu√© esperar?**
```
Python 3.12.0  # O cualquier versi√≥n 3.8+
```

**Si no funciona:**
- Descarga Python desde https://www.python.org/downloads/
- En Windows: Marca la opci√≥n "Add Python to PATH" durante instalaci√≥n
- Reinicia tu terminal despu√©s de instalar

---

### Paso 1.2: Navega al directorio del proyecto

**Windows:**
```cmd
cd C:\Users\jhonnconnor367\PycharmProjects\dokerizacion
```

**Linux/Mac:**
```bash
cd /ruta/donde/clonaste/dokerizacion
```

**Verifica que est√°s en el lugar correcto:**
```bash
dir  # Windows
ls   # Linux/Mac
```

**Deber√≠as ver:**
```
ejercicio_1_1.py
ejercicio_1_2.py
...
Dockerfile
requirements.txt
README.md
```

---

### Paso 1.3: Crea un entorno virtual

**¬øPor qu√©?**
Un entorno virtual a√≠sla las dependencias de este proyecto de tu instalaci√≥n global de Python. Es como tener un Python "privado" solo para este proyecto.

**Windows:**
```cmd
python -m venv .venv
```

**Linux/Mac:**
```bash
python3 -m venv .venv
```

**¬øQu√© acabas de hacer?**
Creaste una carpeta `.venv` que contiene una copia limpia de Python y pip.

---

### Paso 1.4: Activa el entorno virtual

**Windows (CMD):**
```cmd
.venv\Scripts\activate
```

**Windows (PowerShell):**
```powershell
.venv\Scripts\Activate.ps1
```

**Si PowerShell te da error de permisos:**
```powershell
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
```
Luego intenta activar de nuevo.

**Linux/Mac:**
```bash
source .venv/bin/activate
```

**¬øC√≥mo saber si funcion√≥?**
Tu terminal deber√≠a mostrar `(.venv)` al inicio de la l√≠nea:
```
(.venv) C:\Users\jhonnconnor367\PycharmProjects\dokerizacion>
```

---

### Paso 1.5: Actualiza pip

**Todos los sistemas:**
```bash
python -m pip install --upgrade pip
```

**¬øPor qu√©?**
Asegura que tienes la √∫ltima versi√≥n del instalador de paquetes.

---

### Paso 1.6: Instala las dependencias del proyecto

```bash
pip install -r requirements.txt
```

**Esto instalar√°:**
- FastAPI (para crear APIs)
- Transformers (para usar modelos de NLP)
- PyTorch (framework de deep learning)
- Pandas (para manipular datos)
- Y 15+ librer√≠as m√°s...

**Tiempo estimado:** 5-10 minutos (dependiendo de tu conexi√≥n)

**¬øC√≥mo saber que funcion√≥?**
```bash
pip list
```

Deber√≠as ver una lista larga de paquetes instalados incluyendo:
- fastapi
- transformers
- torch
- pandas
- etc.

---

### Paso 1.7: Descarga el modelo de spaCy

Algunos ejercicios usan spaCy para an√°lisis de texto. Necesitas descargar su modelo:

```bash
python -m spacy download en_core_web_sm
```

**¬øQu√© hace esto?**
Descarga un modelo pre-entrenado (50MB) para procesamiento de lenguaje natural en ingl√©s.

---

### ‚úÖ Verificaci√≥n de la Fase 1

Ejecuta estos comandos para verificar que todo est√° bien:

```bash
python -c "import fastapi; print('FastAPI OK')"
python -c "import transformers; print('Transformers OK')"
python -c "import torch; print('PyTorch OK')"
python -c "import spacy; print('spaCy OK')"
```

**Si todos imprimen "OK", ¬°est√°s listo para continuar!**

---

## üéì Fase 2: Ejecutando los Ejercicios (M√≥dulos 1-4)

### ¬øC√≥mo est√°n organizados los ejercicios?

```
M√≥dulo 1 (Fundamentos Python):
  - ejercicio_1_1.py  # Configuraci√≥n de asistentes IA
  - ejercicio_1_2.py  # Programaci√≥n as√≠ncrona
  - ejercicio_1_3.py  # Context managers

M√≥dulo 2 (Recolecci√≥n de Datos):
  - ejercicio_2_1.py  # APIs financieras
  - ejercicio_2_2.py  # Web scraping
  - ejercicio_2_3.py  # Limpieza y OAuth

M√≥dulo 3 (NLP Moderno):
  - ejercicio_3_1.py  # FinBERT sentiment
  - ejercicio_3_2.py  # NER y POS tagging
  - ejercicio_3_3.py  # Text generation

M√≥dulo 4 (NLP Financiero):
  - ejercicio_4_1.py  # Extracci√≥n de datos
  - ejercicio_4_2.py  # An√°lisis de sentimiento
  - ejercicio_4_3.py  # Predicci√≥n con LSTM

M√≥dulo 5 (Producci√≥n):
  - ejercicio_5_1.py  # API con FastAPI
  - ejercicio_5_2_docker_setup.py  # Docker
  - ejercicio_5_3_monitoring.py  # Prometheus
```

---

### Paso 2.1: Ejecuta tu primer ejercicio

```bash
python ejercicio_1_1.py
```

**¬øQu√© hace este ejercicio?**
Configura un asistente de IA (Gemini o DeepSeek) para revisar c√≥digo.

**Si necesitas API keys:**
- Gemini: https://makersuite.google.com/app/apikey
- DeepSeek: https://platform.deepseek.com/

**¬øQu√© deber√≠as ver?**
```
=== Configuraci√≥n de Asistente IA ===
‚úÖ API configurada correctamente
...
```

---

### Paso 2.2: Lee el c√≥digo antes de ejecutar

**IMPORTANTE:** Antes de ejecutar cada ejercicio, √°brelo en tu editor y lee:
1. Los comentarios al inicio (explican qu√© hace)
2. Los docstrings de las funciones
3. Los comentarios inline

**Ejemplo:**
```python
# ejercicio_1_2.py
"""
OBJETIVO: Aprender programaci√≥n as√≠ncrona con async/await
...
"""
```

---

### Paso 2.3: Ejecuta los ejercicios en orden

**M√≥dulo 1:**
```bash
python ejercicio_1_1.py
python ejercicio_1_2.py
python ejercicio_1_3.py
```

**Entre cada ejercicio:**
1. Lee la salida en la terminal
2. Abre el archivo .py y entiende el c√≥digo
3. Modifica algo peque√±o y vuelve a ejecutar
4. Busca los conceptos que no entiendas

**M√≥dulo 2:**
```bash
python ejercicio_2_1.py
python ejercicio_2_2.py
python ejercicio_2_3.py
```

**Nota sobre ejercicio_2_2.py:**
- Usa web scraping, puede tomar tiempo
- Necesitar√°s ChromeDriver si usas Selenium
- Puedes comentar esa parte si solo quieres probar BeautifulSoup

**M√≥dulo 3:**
```bash
python ejercicio_3_1.py  # Primera vez descargar√° FinBERT (~500MB)
python ejercicio_3_2.py
python ejercicio_3_3.py  # Puede tomar tiempo, usa GPU si tienes
```

**‚ö†Ô∏è IMPORTANTE sobre M√≥dulo 3:**
- La primera ejecuci√≥n de 3.1 descargar√° modelos grandes
- Si no tienes GPU, los modelos correr√°n en CPU (m√°s lento pero funciona)
- Ten paciencia, es normal que tarde

**M√≥dulo 4:**
```bash
python ejercicio_4_1.py
python ejercicio_4_2.py
python ejercicio_4_3.py  # LSTM training, puede tomar 10-30 min
```

**‚ö†Ô∏è IMPORTANTE sobre ejercicio_4_3.py:**
- Entrena una red LSTM desde cero
- Puede tomar 10-30 minutos dependiendo de tu CPU/GPU
- Ver√°s una barra de progreso por cada √©poca de entrenamiento

---

### Paso 2.4: Toma notas mientras avanzas

Crea un archivo `mis_notas.md` y escribe:
- ¬øQu√© aprendiste en cada ejercicio?
- ¬øQu√© conceptos te costaron m√°s?
- ¬øQu√© modificaciones hiciste?

**Ejemplo:**
```markdown
## Ejercicio 1.2 - Async/await

Aprend√≠:
- async/await permite ejecutar tareas concurrentemente
- asyncio.gather() corre varias coroutines en paralelo
- Es √∫til para llamadas a APIs que tardan

Dudas:
- ¬øCu√°ndo usar async vs threading?
- ¬øC√≥mo manejo errores en async?
```

---

### ‚úÖ Verificaci√≥n de la Fase 2

Has completado esta fase si:
- ‚úÖ Ejecutaste todos los ejercicios de M√≥dulos 1-4
- ‚úÖ Cada uno corri√≥ sin errores fatales
- ‚úÖ Entiendes (al menos b√°sicamente) qu√© hace cada uno
- ‚úÖ Tienes los modelos descargados (FinBERT, spaCy, etc.)

**No te preocupes si no entiendes TODO a la perfecci√≥n.** La comprensi√≥n profunda viene con la pr√°ctica.

---

## üöÄ Fase 3: Creando tu API con FastAPI

### Paso 3.1: Entiende qu√© es una API REST

**API REST** = Una forma de que programas se comuniquen por internet usando HTTP.

**Analog√≠a:**
Es como un mesero en un restaurante:
- T√∫ (cliente) haces un pedido (request)
- El mesero lo lleva a la cocina (servidor)
- La cocina prepara tu orden (procesamiento)
- El mesero te trae la comida (response)

**FastAPI** = Una librer√≠a de Python que hace s√∫per f√°cil crear estos "meseros".

---

### Paso 3.2: Ejecuta el servidor FastAPI

```bash
python ejercicio_5_1.py
```

**¬øQu√© ver√°s?**
```
INFO:     Started server process [12345]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://127.0.0.1:8000
```

**¬°Tu servidor est√° vivo! üéâ**

---

### Paso 3.3: Prueba tu API

**Opci√≥n 1: Navegador Web**

Abre tu navegador y ve a:
```
http://localhost:8000/docs
```

**¬øQu√© ver√°s?**
La documentaci√≥n interactiva de tu API (Swagger UI). Puedes:
- Ver todos los endpoints disponibles
- Probar cada uno haciendo clic en "Try it out"
- Ver las respuestas en tiempo real

**Opci√≥n 2: Terminal (curl)**

Abre OTRA terminal (deja la del servidor corriendo) y ejecuta:

```bash
curl http://localhost:8000/health
```

**Respuesta esperada:**
```json
{"status": "healthy", "timestamp": "2025-01-11T10:30:00"}
```

**Opci√≥n 3: Postman**

Si tienes Postman:
1. Crea una nueva request GET
2. URL: `http://localhost:8000/health`
3. Click en "Send"

---

### Paso 3.4: Prueba el endpoint de an√°lisis de sentimiento

**En Swagger UI (http://localhost:8000/docs):**

1. Busca el endpoint `POST /analyze/sentiment`
2. Click en "Try it out"
3. En el body JSON, escribe:
```json
{
  "text": "Apple stock is performing great today!"
}
```
4. Click en "Execute"

**Respuesta esperada:**
```json
{
  "sentiment": "positive",
  "score": 0.9234,
  "label": "POSITIVE"
}
```

**¬øQu√© acaba de pasar?**
1. Enviaste texto a tu API
2. Tu API us√≥ el modelo FinBERT
3. El modelo analiz√≥ el sentimiento
4. Te devolvi√≥ el resultado en JSON

**¬°Acabas de hacer tu primera llamada de NLP en producci√≥n!** üéä

---

### Paso 3.5: Explora todos los endpoints

Tu API tiene varios endpoints. Pru√©balos todos en `/docs`:

| Endpoint | M√©todo | ¬øQu√© hace? |
|----------|--------|------------|
| `/health` | GET | Verifica que el servidor est√© vivo |
| `/analyze/sentiment` | POST | Analiza sentimiento de texto |
| `/extract/entities` | POST | Extrae entidades (nombres, empresas) |
| `/predict/price` | POST | Predice tendencia de precio |

---

### Paso 3.6: Det√©n el servidor

Cuando termines de probar, ve a la terminal donde corre el servidor y presiona:
```
Ctrl + C
```

**Ver√°s:**
```
INFO:     Shutting down
INFO:     Finished server shutdown.
```

---

### ‚úÖ Verificaci√≥n de la Fase 3

Has completado esta fase si:
- ‚úÖ Lograste iniciar el servidor FastAPI
- ‚úÖ Accediste a http://localhost:8000/docs
- ‚úÖ Probaste al menos 2 endpoints diferentes
- ‚úÖ Recibiste respuestas JSON v√°lidas
- ‚úÖ Entiendes el flujo b√°sico: request ‚Üí procesamiento ‚Üí response

---

## üê≥ Fase 4: Dockerizaci√≥n

### ¬øPor qu√© Docker?

**El Problema:**
```
Desarrollador: "En mi m√°quina funciona ü§∑"
Servidor: "Aqu√≠ no funciona üí•"
```

**La Soluci√≥n: Docker**
- Empaqueta tu app + todas sus dependencias
- Funciona igual en tu laptop, servidor, nube
- Es el est√°ndar de la industria para despliegue

---

### Paso 4.1: Verifica que Docker est√© instalado

```bash
docker --version
```

**Debes ver algo como:**
```
Docker version 24.0.7, build 24.0.7
```

**Si no est√° instalado:**
- Windows/Mac: Descarga Docker Desktop de https://www.docker.com/products/docker-desktop/
- Linux: `sudo apt-get install docker.io` (Ubuntu/Debian)

**Verifica que Docker est√© corriendo:**
```bash
docker ps
```

Si ves una tabla (aunque est√© vac√≠a), Docker est√° funcionando.

---

### Paso 4.2: Entiende el Dockerfile

Abre el archivo `Dockerfile` en tu editor. Vamos a entenderlo l√≠nea por l√≠nea:

```dockerfile
# Usa Python 3.12 slim (versi√≥n liviana)
FROM python:3.12-slim

# Define el directorio de trabajo dentro del contenedor
WORKDIR /app

# Copia el archivo de dependencias
COPY requirements.txt .

# Instala las dependencias
RUN pip install --no-cache-dir -r requirements.txt

# Descarga el modelo de spaCy
RUN python -m spacy download en_core_web_sm

# Copia todo el c√≥digo de tu app
COPY . .

# Expone el puerto 8000
EXPOSE 8000

# Comando para iniciar el servidor
CMD ["uvicorn", "ejercicio_5_1:app", "--host", "0.0.0.0", "--port", "8000"]
```

**¬øQu√© hace cada parte?**
- `FROM`: Imagen base (Python ya instalado)
- `WORKDIR`: D√≥nde viven tus archivos dentro del contenedor
- `COPY`: Traer archivos de tu m√°quina al contenedor
- `RUN`: Ejecutar comandos durante la construcci√≥n
- `EXPOSE`: Decirle a Docker qu√© puerto usa tu app
- `CMD`: Comando que corre cuando inicias el contenedor

---

### Paso 4.3: Construye la imagen Docker

```bash
docker build -t nlp-api:latest .
```

**¬øQu√© hace este comando?**
- `docker build`: Construye una imagen
- `-t nlp-api:latest`: Le pone nombre y etiqueta
- `.`: Usa el Dockerfile del directorio actual

**Tiempo estimado:** 5-10 minutos

**Ver√°s:**
```
[+] Building 240.5s (12/12) FINISHED
Step 1/8 : FROM python:3.12-slim
Step 2/8 : WORKDIR /app
...
Successfully built abc123def456
Successfully tagged nlp-api:latest
```

**Verifica que la imagen se cre√≥:**
```bash
docker images
```

**Deber√≠as ver:**
```
REPOSITORY   TAG      IMAGE ID       CREATED         SIZE
nlp-api      latest   abc123def456   2 minutes ago   2.1GB
```

---

### Paso 4.4: Ejecuta tu contenedor

```bash
docker run -d -p 8000:8000 --name nlp-container nlp-api:latest
```

**Desglosando el comando:**
- `docker run`: Inicia un contenedor
- `-d`: Modo detached (corre en background)
- `-p 8000:8000`: Mapea puerto 8000 del contenedor ‚Üí 8000 de tu m√°quina
- `--name nlp-container`: Nombre del contenedor
- `nlp-api:latest`: Imagen a usar

**Verifica que est√© corriendo:**
```bash
docker ps
```

**Deber√≠as ver:**
```
CONTAINER ID   IMAGE              STATUS         PORTS                    NAMES
abc123456789   nlp-api:latest     Up 5 seconds   0.0.0.0:8000->8000/tcp   nlp-container
```

---

### Paso 4.5: Prueba tu API Dockerizada

**Abre tu navegador:**
```
http://localhost:8000/docs
```

**Deber√≠as ver la misma UI de Swagger que antes, pero ahora tu app corre dentro de Docker!** üê≥

**Prueba un endpoint:**
```bash
curl http://localhost:8000/health
```

---

### Paso 4.6: Ve los logs del contenedor

```bash
docker logs nlp-container
```

**Ver√°s los mismos logs de Uvicorn:**
```
INFO:     Started server process [1]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8000
```

**Para ver logs en tiempo real:**
```bash
docker logs -f nlp-container
```
(Presiona Ctrl+C para salir)

---

### Paso 4.7: Entra al contenedor (opcional pero educativo)

```bash
docker exec -it nlp-container bash
```

**Ahora est√°s "dentro" del contenedor.** Es como SSH a otra m√°quina.

**Prueba algunos comandos:**
```bash
pwd                    # Ver√°s /app
ls                     # Ver√°s tus archivos Python
python --version       # Ver√°s Python 3.12
pip list               # Ver√°s las dependencias instaladas
exit                   # Para salir
```

---

### Paso 4.8: Det√©n y elimina el contenedor

```bash
# Detener el contenedor
docker stop nlp-container

# Eliminar el contenedor
docker rm nlp-container
```

**Si quieres hacer ambas cosas a la vez:**
```bash
docker rm -f nlp-container
```

---

### ‚úÖ Verificaci√≥n de la Fase 4

Has completado esta fase si:
- ‚úÖ Construiste la imagen Docker sin errores
- ‚úÖ Iniciaste un contenedor correctamente
- ‚úÖ Accediste a http://localhost:8000/docs desde el contenedor
- ‚úÖ Probaste al menos un endpoint
- ‚úÖ Viste los logs del contenedor
- ‚úÖ Entiendes la diferencia entre imagen y contenedor

**Imagen = Plantilla (como un .exe)**
**Contenedor = Instancia corriendo (como un programa abierto)**

---

## üìä Fase 5: Monitoreo y Observabilidad

### ¬øPor qu√© monitorear?

**En producci√≥n necesitas saber:**
- ¬øEst√° mi servicio vivo?
- ¬øQu√© tan r√°pido responde?
- ¬øCu√°ntas requests est√° manejando?
- ¬øSe est√° quedando sin memoria?

**Prometheus** es la herramienta est√°ndar para esto.

---

### Paso 5.1: Ejecuta el ejercicio de monitoreo

```bash
python ejercicio_5_3_monitoring.py
```

**¬øQu√© hace este script?**
- Configura m√©tricas de Prometheus
- Expone un endpoint `/metrics`
- Simula tr√°fico y captura estad√≠sticas

**Deber√≠as ver:**
```
=== Sistema de Monitoreo con Prometheus ===
‚úÖ Servidor iniciado en http://localhost:8000
‚úÖ M√©tricas disponibles en http://localhost:8000/metrics
...
```

---

### Paso 5.2: Ve las m√©tricas crudas

Abre tu navegador:
```
http://localhost:8000/metrics
```

**Ver√°s algo como:**
```
# HELP nlp_requests_total Total number of NLP requests
# TYPE nlp_requests_total counter
nlp_requests_total{endpoint="/analyze"} 42.0

# HELP nlp_request_duration_seconds Request duration
# TYPE nlp_request_duration_seconds histogram
nlp_request_duration_seconds_bucket{le="0.1"} 35.0
nlp_request_duration_seconds_bucket{le="0.5"} 42.0
...
```

**Estos son los datos que Prometheus consumir√≠a.**

---

### Paso 5.3: Entiende las m√©tricas principales

**Contador (Counter):**
```python
nlp_requests_total{endpoint="/analyze"} 42.0
```
‚Üí Se ha llamado 42 veces al endpoint `/analyze`

**Histograma (Histogram):**
```python
nlp_request_duration_seconds_bucket{le="0.5"} 42.0
```
‚Üí 42 requests tomaron ‚â§ 0.5 segundos

**Gauge (Medidor):**
```python
nlp_active_requests 5.0
```
‚Üí Hay 5 requests proces√°ndose ahora mismo

---

### Paso 5.4: Integra monitoreo en tu API

El archivo `ejercicio_5_1.py` ya tiene monitoreo integrado. B√∫scalo:

```python
from prometheus_client import Counter, Histogram, generate_latest

# Definir m√©tricas
REQUEST_COUNT = Counter('api_requests_total', 'Total API requests')
REQUEST_DURATION = Histogram('api_request_duration_seconds', 'Request duration')

@app.get("/metrics")
def metrics():
    return Response(generate_latest(), media_type="text/plain")
```

**¬°Tu API ya est√° instrumentada para Prometheus!**

---

### ‚úÖ Verificaci√≥n de la Fase 5

Has completado esta fase si:
- ‚úÖ Ejecutaste el script de monitoreo
- ‚úÖ Accediste a `/metrics` y viste datos
- ‚úÖ Entiendes qu√© es un Counter, Histogram y Gauge
- ‚úÖ Sabes que estos datos los consumir√≠a Prometheus

**Nota:** No vamos a instalar Prometheus completo (es complejo), pero tu API ya est√° preparada para cuando lo necesites.

---

## üéº Fase 6: Despliegue Completo con Docker Compose

### ¬øQu√© es Docker Compose?

**Docker Compose** = Orquestar m√∫ltiples contenedores como una sola aplicaci√≥n.

**Ejemplo:**
- Contenedor 1: Tu API FastAPI
- Contenedor 2: Base de datos PostgreSQL
- Contenedor 3: Redis (cach√©)
- Contenedor 4: Prometheus (monitoreo)
- Contenedor 5: Nginx (reverse proxy)

**Todos funcionando juntos.**

---

### Paso 6.1: Entiende el archivo docker-compose.yml

Abre `docker-compose.yml`:

```yaml
version: '3.8'

services:
  api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://user:pass@db:5432/nlpdb
    depends_on:
      - db
      - redis

  db:
    image: postgres:15
    environment:
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=pass
      - POSTGRES_DB=nlpdb

  redis:
    image: redis:7-alpine

  prometheus:
    image: prom/prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
```

**¬øQu√© define cada secci√≥n?**
- `api`: Tu aplicaci√≥n FastAPI
- `db`: Base de datos PostgreSQL
- `redis`: Cach√© en memoria
- `prometheus`: Sistema de monitoreo
- `nginx`: Proxy inverso (punto de entrada)

---

### Paso 6.2: Completa las configuraciones (TODO)

El archivo tiene TODOs marcados. Vamos a completarlos:

**TODO 1: Variables de entorno para la API**

Crea un archivo `.env` en el directorio ra√≠z:

```bash
# .env
DATABASE_URL=postgresql://nlpuser:nlppassword@db:5432/nlpdb
REDIS_URL=redis://redis:6379/0
API_SECRET_KEY=tu-clave-secreta-super-segura-cambiame
```

**TODO 2: Configuraci√≥n de Prometheus**

Crea `prometheus.yml`:

```yaml
# prometheus.yml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'nlp-api'
    static_configs:
      - targets: ['api:8000']
    metrics_path: '/metrics'
```

**TODO 3: Configuraci√≥n de Nginx**

Crea `nginx.conf`:

```nginx
# nginx.conf
events {
    worker_connections 1024;
}

http {
    upstream api {
        server api:8000;
    }

    server {
        listen 80;

        location / {
            proxy_pass http://api;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
        }
    }
}
```

---

### Paso 6.3: Actualiza docker-compose.yml para usar las configs

Edita `docker-compose.yml` y reemplaza las secciones:

```yaml
version: '3.8'

services:
  api:
    build: .
    ports:
      - "8000:8000"
    env_file:
      - .env
    depends_on:
      - db
      - redis
    restart: unless-stopped

  db:
    image: postgres:15
    environment:
      POSTGRES_USER: nlpuser
      POSTGRES_PASSWORD: nlppassword
      POSTGRES_DB: nlpdb
    volumes:
      - postgres_data:/var/lib/postgresql/data
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    restart: unless-stopped

  prometheus:
    image: prom/prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    restart: unless-stopped

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - api
    restart: unless-stopped

volumes:
  postgres_data:
  prometheus_data:
```

---

### Paso 6.4: Levanta todo el stack

```bash
docker-compose up -d
```

**¬øQu√© hace este comando?**
- Construye las im√°genes necesarias
- Inicia todos los contenedores
- Los conecta en una red privada
- `-d`: Corre en background

**Tiempo estimado:** 3-5 minutos (primera vez)

**Ver√°s:**
```
Creating network "dokerizacion_default"
Creating volume "dokerizacion_postgres_data"
Creating dokerizacion_db_1         ... done
Creating dokerizacion_redis_1      ... done
Creating dokerizacion_api_1        ... done
Creating dokerizacion_prometheus_1 ... done
Creating dokerizacion_nginx_1      ... done
```

---

### Paso 6.5: Verifica que todo est√© corriendo

```bash
docker-compose ps
```

**Deber√≠as ver algo como:**
```
NAME                    IMAGE              STATUS    PORTS
dokerizacion_api_1      nlp-api:latest     Up        0.0.0.0:8000->8000/tcp
dokerizacion_db_1       postgres:15        Up        5432/tcp
dokerizacion_redis_1    redis:7-alpine     Up        6379/tcp
dokerizacion_prometheus_1 prom/prometheus  Up        0.0.0.0:9090->9090/tcp
dokerizacion_nginx_1    nginx:alpine       Up        0.0.0.0:80->80/tcp
```

**Todos deben tener STATUS = "Up"**

---

### Paso 6.6: Prueba el sistema completo

**1. API a trav√©s de Nginx (puerto 80):**
```
http://localhost/docs
```

**2. API directa (puerto 8000):**
```
http://localhost:8000/docs
```

**3. Prometheus (puerto 9090):**
```
http://localhost:9090
```

En Prometheus:
- Ve a "Status" ‚Üí "Targets"
- Deber√≠as ver `nlp-api` con estado "UP"
- Ve a "Graph" y escribe: `api_requests_total`
- Click "Execute" para ver la m√©trica

**4. Haz algunas requests para generar datos:**

```bash
curl -X POST http://localhost/analyze/sentiment \
  -H "Content-Type: application/json" \
  -d '{"text": "The market is looking great!"}'
```

Repite varias veces y luego refresca Prometheus.

---

### Paso 6.7: Ve los logs de todos los servicios

```bash
# Logs de todos los servicios
docker-compose logs

# Logs solo de la API
docker-compose logs api

# Logs en tiempo real
docker-compose logs -f api
```

---

### Paso 6.8: Det√©n todo el stack

```bash
docker-compose down
```

**Para eliminar tambi√©n los vol√∫menes (base de datos):**
```bash
docker-compose down -v
```

---

### ‚úÖ Verificaci√≥n de la Fase 6

Has completado esta fase si:
- ‚úÖ Levantaste todo el stack con `docker-compose up`
- ‚úÖ Todos los contenedores est√°n "Up"
- ‚úÖ Accediste a la API v√≠a Nginx (puerto 80)
- ‚úÖ Viste m√©tricas en Prometheus (puerto 9090)
- ‚úÖ Hiciste requests y las m√©tricas se actualizaron
- ‚úÖ Detuviste todo con `docker-compose down`

**¬°Felicitaciones! Acabas de desplegar un sistema completo de microservicios. üéâ**

---

## üîß Soluci√≥n de Problemas Comunes

### Problema 1: "ModuleNotFoundError: No module named 'fastapi'"

**Causa:** No activaste el entorno virtual o no instalaste dependencias.

**Soluci√≥n:**
```bash
# Activa el entorno virtual
.venv\Scripts\activate  # Windows
source .venv/bin/activate  # Linux/Mac

# Instala dependencias
pip install -r requirements.txt
```

---

### Problema 2: "Port 8000 is already in use"

**Causa:** Ya hay algo corriendo en el puerto 8000.

**Soluci√≥n Windows:**
```cmd
# Encuentra qu√© proceso usa el puerto
netstat -ano | findstr :8000

# Mata el proceso (reemplaza PID con el n√∫mero que viste)
taskkill /PID <PID> /F
```

**Soluci√≥n Linux/Mac:**
```bash
# Encuentra el proceso
lsof -i :8000

# Mata el proceso
kill -9 <PID>
```

**O simplemente usa otro puerto:**
```bash
uvicorn ejercicio_5_1:app --port 8001
```

---

### Problema 3: Docker build falla con "No space left on device"

**Causa:** Docker se qued√≥ sin espacio.

**Soluci√≥n:**
```bash
# Limpia contenedores e im√°genes no usados
docker system prune -a

# Limpia vol√∫menes
docker volume prune
```

---

### Problema 4: Transformers descarga modelos muy lento

**Causa:** Conexi√≥n lenta o servidor de Hugging Face saturado.

**Soluci√≥n:**
```python
# Usa cache local si ya descargaste antes
from transformers import pipeline
classifier = pipeline('sentiment-analysis',
                     model='ProsusAI/finbert',
                     local_files_only=True)  # Solo usar cache local
```

---

### Problema 5: "RuntimeError: CUDA out of memory"

**Causa:** Est√°s intentando usar GPU pero no hay memoria suficiente.

**Soluci√≥n:**
```python
# Fuerza uso de CPU
import torch
device = torch.device("cpu")

# Al cargar modelos
model = AutoModel.from_pretrained("ProsusAI/finbert").to(device)
```

---

### Problema 6: Docker Compose no encuentra archivo .env

**Causa:** El archivo .env no est√° en el directorio correcto.

**Soluci√≥n:**
```bash
# El .env debe estar en el mismo directorio que docker-compose.yml
cd C:\Users\jhonnconnor367\PycharmProjects\dokerizacion

# Verifica que existe
dir .env  # Windows
ls -la .env  # Linux/Mac

# Si no existe, cr√©alo
echo DATABASE_URL=postgresql://nlpuser:nlppassword@db:5432/nlpdb > .env
```

---

### Problema 7: PostgreSQL no acepta conexiones

**Causa:** El contenedor de la DB no termin√≥ de inicializarse.

**Soluci√≥n:**
```bash
# Ve los logs
docker-compose logs db

# Espera a ver este mensaje:
# "database system is ready to accept connections"

# Si tarda mucho, reinicia
docker-compose restart db
```

---

### Problema 8: Prometheus no scrapes las m√©tricas

**Causa:** Configuraci√≥n incorrecta de prometheus.yml o la API no expone /metrics.

**Soluci√≥n:**

1. Verifica que la API exponga m√©tricas:
```bash
curl http://localhost:8000/metrics
```

2. Verifica prometheus.yml:
```yaml
scrape_configs:
  - job_name: 'nlp-api'
    static_configs:
      - targets: ['api:8000']  # ‚Üê Debe ser 'api', no 'localhost'
```

3. Reinicia Prometheus:
```bash
docker-compose restart prometheus
```

---

## ‚úÖ Verificaci√≥n y Testing

### Checklist Final

Antes de dar por terminado el proyecto, verifica:

**Entorno Local:**
- [ ] Entorno virtual activo
- [ ] Todas las dependencias instaladas
- [ ] Modelos de NLP descargados (FinBERT, spaCy)

**Ejercicios:**
- [ ] M√≥dulo 1 (1.1, 1.2, 1.3) completados
- [ ] M√≥dulo 2 (2.1, 2.2, 2.3) completados
- [ ] M√≥dulo 3 (3.1, 3.2, 3.3) completados
- [ ] M√≥dulo 4 (4.1, 4.2, 4.3) completados

**API Local:**
- [ ] Servidor FastAPI inicia sin errores
- [ ] `/docs` accesible y funcional
- [ ] Al menos 3 endpoints probados exitosamente
- [ ] `/metrics` expone datos de Prometheus

**Docker:**
- [ ] Imagen construida exitosamente
- [ ] Contenedor corre sin errores
- [ ] API accesible desde contenedor
- [ ] Logs visibles con `docker logs`

**Docker Compose:**
- [ ] Todos los servicios (api, db, redis, prometheus, nginx) corren
- [ ] API accesible v√≠a Nginx (puerto 80)
- [ ] Prometheus scrapes m√©tricas (puerto 9090)
- [ ] Base de datos acepta conexiones

**Documentaci√≥n:**
- [ ] README.md le√≠do completamente
- [ ] DIAPOSITIVAS.md revisado
- [ ] Esta gu√≠a seguida paso a paso

---

### Script de Testing Automatizado

Crea un archivo `test_deployment.py`:

```python
"""
Script para verificar que todo el despliegue funciona correctamente.
"""
import requests
import time

def test_api_health():
    """Verifica que la API est√© viva"""
    try:
        response = requests.get("http://localhost:8000/health", timeout=5)
        assert response.status_code == 200
        print("‚úÖ API health check: OK")
        return True
    except Exception as e:
        print(f"‚ùå API health check: FAILED - {e}")
        return False

def test_sentiment_analysis():
    """Verifica an√°lisis de sentimiento"""
    try:
        payload = {"text": "The stock market is doing great!"}
        response = requests.post("http://localhost:8000/analyze/sentiment",
                                json=payload, timeout=10)
        assert response.status_code == 200
        data = response.json()
        assert "sentiment" in data
        print(f"‚úÖ Sentiment analysis: OK (sentiment={data['sentiment']})")
        return True
    except Exception as e:
        print(f"‚ùå Sentiment analysis: FAILED - {e}")
        return False

def test_metrics():
    """Verifica que las m√©tricas est√©n disponibles"""
    try:
        response = requests.get("http://localhost:8000/metrics", timeout=5)
        assert response.status_code == 200
        assert "api_requests_total" in response.text
        print("‚úÖ Prometheus metrics: OK")
        return True
    except Exception as e:
        print(f"‚ùå Prometheus metrics: FAILED - {e}")
        return False

def test_prometheus():
    """Verifica que Prometheus est√© corriendo"""
    try:
        response = requests.get("http://localhost:9090/-/healthy", timeout=5)
        assert response.status_code == 200
        print("‚úÖ Prometheus server: OK")
        return True
    except Exception as e:
        print(f"‚ùå Prometheus server: FAILED - {e}")
        return False

def main():
    print("=== Testing Deployment ===\n")

    tests = [
        test_api_health,
        test_sentiment_analysis,
        test_metrics,
        test_prometheus
    ]

    results = [test() for test in tests]

    print(f"\n=== Results: {sum(results)}/{len(results)} tests passed ===")

    if all(results):
        print("üéâ ¬°Todo funciona correctamente!")
        return 0
    else:
        print("‚ö†Ô∏è  Algunos tests fallaron. Revisa los errores arriba.")
        return 1

if __name__ == "__main__":
    exit(main())
```

**Ejecuta el test:**
```bash
# Primero levanta el stack
docker-compose up -d

# Espera 30 segundos para que todo inicie
sleep 30

# Ejecuta los tests
python test_deployment.py
```

---

## üöÄ Pr√≥ximos Pasos

### Has completado el proyecto base. ¬øQu√© sigue?

#### Nivel 1: Mejoras R√°pidas (1-2 horas cada una)

1. **Agregar autenticaci√≥n JWT**
   - Protege tus endpoints con tokens
   - Ejercicio 5.1 tiene ejemplos comentados

2. **Implementar rate limiting**
   - Prevenir abuso de la API
   - Usa `slowapi` o Redis

3. **Agregar logging estructurado**
   - Reemplaza prints con `logging`
   - Usa formato JSON para logs

4. **Crear tests unitarios**
   - Usa `pytest`
   - Cubre al menos los endpoints principales

#### Nivel 2: Mejoras Intermedias (4-8 horas cada una)

5. **Base de datos real**
   - Implementa SQLAlchemy o SQLModel
   - Guarda resultados de an√°lisis en PostgreSQL
   - Crea endpoints para consultar hist√≥rico

6. **Cache con Redis**
   - Cachea resultados de modelos pesados
   - Reduce tiempo de respuesta en 50-80%

7. **Async task queue**
   - Usa Celery + Redis
   - Procesa an√°lisis largos en background

8. **CI/CD con GitHub Actions**
   - Automatiza tests
   - Construye y publica imagen Docker autom√°ticamente

#### Nivel 3: Proyectos Avanzados (1-2 semanas)

9. **Dashboard interactivo con Streamlit**
   - Visualiza tendencias de sentimiento
   - Gr√°ficos en tiempo real

10. **Despliegue en la nube**
    - AWS ECS o Google Cloud Run
    - Configura dominio y HTTPS
    - Implementa auto-scaling

11. **Agregador de m√∫ltiples fuentes**
    - Twitter API para tweets en tiempo real
    - NewsAPI para art√≠culos de noticias
    - Yahoo Finance para datos de mercado

12. **Sistema de alertas**
    - Notificaciones cuando sentimiento cambia dr√°sticamente
    - Integraci√≥n con Slack, Email, Telegram

---

### Recursos para Continuar Aprendiendo

**Documentaci√≥n:**
- FastAPI: https://fastapi.tiangolo.com/tutorial/
- Transformers: https://huggingface.co/course
- Docker: https://docs.docker.com/get-started/

**Cursos (gratis):**
- FastAPI Full Tutorial: YouTube (freeCodeCamp)
- Hugging Face NLP Course: https://huggingface.co/learn/nlp-course
- Docker for Beginners: Docker.com

**Libros:**
- "FastAPI - Modern Python Web Development" (Bill Lubanovic)
- "Natural Language Processing with Transformers" (Lewis Tunstall)
- "Docker Deep Dive" (Nigel Poulton)

**Comunidades:**
- r/FastAPI (Reddit)
- Hugging Face Discord
- Docker Community Forums

---

## üéì Certificaci√≥n de Completitud

**Si llegaste hasta aqu√≠ y completaste todas las fases, ¬°felicitaciones!**

Has demostrado que puedes:
- ‚úÖ Configurar entornos Python profesionales
- ‚úÖ Implementar modelos de NLP state-of-the-art
- ‚úÖ Crear APIs REST con FastAPI
- ‚úÖ Dockerizar aplicaciones
- ‚úÖ Orquestar m√∫ltiples servicios con Docker Compose
- ‚úÖ Implementar monitoreo y observabilidad
- ‚úÖ Seguir gu√≠as t√©cnicas y resolver problemas

**Estas habilidades son valiosas en:**
- Ingeniero de Machine Learning
- Backend Developer
- MLOps Engineer
- Data Engineer
- DevOps Engineer

---

## üìù Feedback y Contribuciones

**¬øEncontraste un error en esta gu√≠a?**
- Abre un issue en el repo

**¬øTienes sugerencias de mejora?**
- Env√≠a un pull request

**¬øCompletaste el proyecto?**
- Comparte tu experiencia: ¬øqu√© aprendiste? ¬øqu√© fue dif√≠cil?

---

## üôè Agradecimientos

Esta gu√≠a fue creada para ayudar a desarrolladores a dar el salto de "c√≥digo que funciona localmente" a "servicios en producci√≥n".

Si esta gu√≠a te ayud√≥, considera:
- ‚≠ê Darle estrella al repositorio
- üì¢ Compartirla con otros desarrolladores
- üí¨ Dejar feedback para mejorarla

---

**¬°√âxito en tu viaje de aprendizaje! üöÄ**

---

**√öltima actualizaci√≥n:** Enero 2025
**Versi√≥n:** 1.0
**Proyecto:** Del C√≥digo al Despliegue - NLP en Producci√≥n
